{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "fPNNhkBK0VJZFbeN2cKnaV",
     "report_properties": {
      "rowId": "u6LTQPlOHwjW8QonAlWPRw"
     },
     "type": "MD"
    }
   },
   "source": [
    "# Unsupervised Models with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "7q43rGAbn0aKlAqAvgCS4n",
     "report_properties": {
      "rowId": "TMyR1M476aRvAtdEJ2lB2o"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ianpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\umap\\distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\ianpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\umap\\distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\ianpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\umap\\distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "C:\\Users\\ianpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\umap\\umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "baaphjw5dZasicIrLM7leU",
     "type": "MD"
    }
   },
   "source": [
    "# Initialize the LSA dataframe from previous steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "BMZX8KLMFuaMLJyTk9DhIS",
     "report_properties": {
      "rowId": "Iir7b60B1v22iZarirWbAl"
     },
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "lsa_category = pd.read_csv(\"SVD_reuters_df.csv\", index_col=0)\n",
    "#lsa_category"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataframe for Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "1kWjOmd2C3SjaJiPonfky1",
     "report_properties": {
      "rowId": "SFuRaLB9ZRvpo7Z2MBoVcy"
     },
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "earn            981\n",
      "acq             573\n",
      "crude            93\n",
      "trade            82\n",
      "money-fx         77\n",
      "interest         68\n",
      "money-supply     38\n",
      "ship             36\n",
      "sugar            31\n",
      "coffee           28\n",
      "gold             23\n",
      "cpi              18\n",
      "gnp              18\n",
      "cocoa            15\n",
      "grain            13\n",
      "reserves         12\n",
      "jobs             12\n",
      "alum             12\n",
      "ipi              11\n",
      "copper           11\n",
      "rubber           10\n",
      "iron-steel        9\n",
      "nat-gas           9\n",
      "bop               8\n",
      "veg-oil           8\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "earn            2942\n",
      "acq             1719\n",
      "crude            281\n",
      "trade            244\n",
      "money-fx         232\n",
      "interest         204\n",
      "money-supply     113\n",
      "ship             108\n",
      "sugar             91\n",
      "coffee            84\n",
      "gold              67\n",
      "gnp               56\n",
      "cpi               53\n",
      "cocoa             46\n",
      "grain             38\n",
      "alum              38\n",
      "reserves          37\n",
      "jobs              37\n",
      "ipi               34\n",
      "copper            33\n",
      "rubber            30\n",
      "iron-steel        29\n",
      "nat-gas           27\n",
      "bop               23\n",
      "veg-oil           22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Establish outcome and predictors\n",
    "y = lsa_category['category']\n",
    "X = lsa_category.drop(columns=['category'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Make sure classes are balanced after train-test-split\n",
    "print(y_test.value_counts())\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Techniques\n",
    "\n",
    "In our project, we also explored the application of unsupervised learning models, which is another category of machine learning algorithms. Unlike supervised learning models, unsupervised models work with datasets that do not have pre-existing labels or targets. The aim of these models is to identify patterns, structures, or relationships within the data that are not immediately evident.\n",
    "\n",
    "Unsupervised models can perform tasks such as clustering, where data is grouped based on similarities, or dimensionality reduction, where complex data is simplified while preserving its key structure. For instance, we used algorithms such as K-means for clustering and Gaussian Mixture Models (GMM).\n",
    "\n",
    "These unsupervised models helped us uncover hidden patterns and structures within our data, which enriched our understanding of the data and provided insightful inputs for our supervised models. Despite not directly contributing to the predictive power of our system, the unsupervised models proved invaluable for exploratory analysis and feature engineering stages of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_unsupervised(model, param_grid, X):\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "    grid_search.fit(X)\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    cv_scores = grid_search.cv_results_ \n",
    "    y_predicted = best_estimator.predict(X)\n",
    "\n",
    "    return y_predicted, best_params, best_score, cv_scores\n",
    "\n",
    "def get_acc_cm(labels_encoded, y_pred):\n",
    "    acc_score = accuracy_score(labels_encoded, y_pred)\n",
    "    cm = confusion_matrix(labels_encoded, y_pred)\n",
    "    return acc_score, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels_encoded = le.fit_transform(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans\n",
    "\n",
    "K-means is a simple and widely-used clustering algorithm that partitions the dataset into K distinct, non-overlapping clusters based on the similarity between data points. The algorithm iteratively assigns each data point to the nearest cluster's centroid and updates the centroid's position by averaging the positions of all points within the cluster. The process continues until convergence or a predefined number of iterations. K-means is computationally efficient and works well with large datasets. However, it assumes that clusters are spherical and have similar sizes, which may not always hold true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'init': 'k-means++', 'max_iter': 40, 'n_clusters': 25, 'n_init': 40}\n",
      "Best score: -1353.1186145429328\n",
      "Accuracy score:  0.038706739526411654\n",
      "Confusion matrix:\n",
      " [[  6   0   0   0   1   3  13  11 396   0   0 888   1   4 366   0 378   0\n",
      "    0 176  34   0  14   1   0]\n",
      " [  0   0   0   0   0   0   0   0  34   0   1   0   0  15   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   3   0   0   4   0  22   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1  45   0   0   0   0  15   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   6   0   0   0   0   2   0   0   0   0\n",
      "    0   0   1   0   0 103   0]\n",
      " [  0   0   0   0   0   0   0   0  31   0   0   9   0   4   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  62   0   0   6   0   0   0   0   0   0   0   0   0\n",
      "    1   0   1   0   1   0   0]\n",
      " [  1   0   0   0   0   0   1   2  56   0   0   3   0   1   1   0   1  77\n",
      "    0   0   0   0 231   0   0]\n",
      " [  0 459 306 480 279  21  72 349 332 367 161  49 220   2   3 148  80   0\n",
      "    0   0  35 308  10   0 242]\n",
      " [  1   0   0   0   0  45   0   2  23   0   1   0   0   0   0   0   0   0\n",
      "    0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0  29   0   0   0   0  59   0   0   1   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   2   0   0  35   0   0   0   0  12   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  3   0   0   0   0  20   2   0  43   0   3   0   0   0   0   0   0   0\n",
      "   20   0 181   0   0   0   0]\n",
      " [  1   0   0   0   0  39   0   0   5   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0  25   0   2   3   0   6   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  34   0   1  12   0   0   0   0   0   0   0   0   0\n",
      "    0   0   2   0   0   0   0]\n",
      " [ 15   0   0   0   0   2  58   0 141   0   5   0   0   0   0   0   0   0\n",
      "   19   0  69   0   0   0   0]\n",
      " [  0   0   0   0   0  33   5   0  14   0  38   0   0   0   0   0   0   0\n",
      "   41   0  20   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  26   0   0   4   0   0   1   0   0   0\n",
      "    0   0   0   0   5   0   0]\n",
      " [  0   0   0   0   0   3   0   0   5   0  39   0   0   0   0   0   0   0\n",
      "    0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  34   0   0   1   0   5   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 135   0   0   4   0   5   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  11   0   0   0   0 111   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [253   0   0   0   0   9   0   0  30   0  29   0   0   0   0   0   0   0\n",
      "    0   0   4   0   1   0   0]\n",
      " [  4   0   0   0   0   0   0   0  21   0   0   0   0   4   0   0   0   0\n",
      "    0   0   0   0   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#Create a Kmeans model\n",
    "kmeans = KMeans()\n",
    "\n",
    "# define the hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'n_clusters': [y.nunique()],\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'n_init': [10, 20, 30, 40, 50],\n",
    "    'max_iter': [10, 20, 30, 40, 50]\n",
    "}\n",
    "y_predicted, best_params, best_score, cv_scores = process_unsupervised(kmeans, param_grid, X)\n",
    "acc_score, cm = get_acc_cm(labels_encoded, y_predicted)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Accuracy score: \", acc_score)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Model (GMM)\n",
    "\n",
    "GMM is a probabilistic model that assumes that the data points are generated from a mixture of several Gaussian distributions. The algorithm estimates the parameters of these distributions, such as means, covariances, and the mixture weights, using an iterative process called Expectation-Maximization (EM). GMM is more flexible than K-means, as it can model clusters with different shapes, sizes, and orientations. However, it is more computationally expensive and may not scale well to large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'covariance_type' for estimator KMeans(). Valid parameters are: ['algorithm', 'copy_x', 'init', 'max_iter', 'n_clusters', 'n_init', 'random_state', 'tol', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 674, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\base.py\", line 205, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'covariance_type' for estimator KMeans(). Valid parameters are: ['algorithm', 'copy_x', 'init', 'max_iter', 'n_clusters', 'n_init', 'random_state', 'tol', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# define the hyperparameter grid to search over\u001b[39;00m\n\u001b[0;32m      5\u001b[0m param_grid \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mn_components\u001b[39m\u001b[39m'\u001b[39m: [y\u001b[39m.\u001b[39mnunique()], \n\u001b[0;32m      6\u001b[0m               \u001b[39m'\u001b[39m\u001b[39mcovariance_type\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtied\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdiag\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mspherical\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m----> 7\u001b[0m y_predicted, best_params, best_score, cv_scores \u001b[39m=\u001b[39m process_unsupervised(kmeans, param_grid, X)\n\u001b[0;32m      8\u001b[0m acc_score, cm \u001b[39m=\u001b[39m get_acc_cm(labels_encoded, y_predicted)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest parameters:\u001b[39m\u001b[39m\"\u001b[39m, best_params)\n",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m, in \u001b[0;36mprocess_unsupervised\u001b[1;34m(model, param_grid, X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_unsupervised\u001b[39m(model, param_grid, X):\n\u001b[0;32m      3\u001b[0m     grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     grid_search\u001b[39m.\u001b[39;49mfit(X)\n\u001b[0;32m      5\u001b[0m     best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m      6\u001b[0m     best_score \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\alexa\\mambaforge\\envs\\machinelearning2\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'covariance_type' for estimator KMeans(). Valid parameters are: ['algorithm', 'copy_x', 'init', 'max_iter', 'n_clusters', 'n_init', 'random_state', 'tol', 'verbose']."
     ]
    }
   ],
   "source": [
    "# Create a GMM model\n",
    "gmm = GaussianMixture(random_state=42)\n",
    "\n",
    "# define the hyperparameter grid to search over\n",
    "param_grid = {'n_components': [y.nunique()], \n",
    "              'covariance_type': ['full', 'tied', 'diag', 'spherical']}\n",
    "y_predicted, best_params, best_score, cv_scores = process_unsupervised(gmm, param_grid, X)\n",
    "acc_score, cm = get_acc_cm(labels_encoded, y_predicted)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Accuracy score: \", acc_score)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_map = {}\n",
    "cross_validation = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=y.nunique())\n",
    "\n",
    "scores = cross_val_score(kmeans, X, cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['KMM'] = scores\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(random_state=42, n_components=y.nunique())\n",
    "\n",
    "scores = cross_val_score(gmm, X, cv=cross_validation, scoring='neg_mean_squared_error')\n",
    "print(f\"MSE: {scores.mean()} (+/- {scores.std()})\")\n",
    "\n",
    "scores_map['GMM'] = scores\n",
    "scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "nltk",
     "source": "PIP",
     "version": "3.8.1"
    },
    {
     "name": "umap",
     "source": "PIP",
     "version": "0.1.1"
    },
    {
     "name": "umap-learn",
     "source": "PIP",
     "version": "0.5.3"
    }
   ],
   "report_row_ids": [
    "u6LTQPlOHwjW8QonAlWPRw",
    "TMyR1M476aRvAtdEJ2lB2o",
    "Iir7b60B1v22iZarirWbAl",
    "sJabOn0ov4ZjSMq4aEyDCl",
    "HjsgnIODGokPkzsajLQEgS",
    "gNsM6o95VGG4nbvSzdMBon",
    "ScJ0R81K8crwRDJXv8G1jG",
    "h8Msz74vM0OFAR31JPsQlc",
    "N5f92IE0uqWUizQRMMENuB",
    "3n6ntJTkKE1oX1COvJOhZj",
    "ae3yd1HgokN38tbO7tDeiJ",
    "OMCT04A6OyZsO9mFp3p9Rw",
    "utWL8XT1ZTwd5O6zB4p4hS",
    "LXXrkRCuqPA5ioDjltPr54",
    "6AVGn0iWD84qvj59L17YO7",
    "SFuRaLB9ZRvpo7Z2MBoVcy",
    "gBLhVS6bPl5nfOrDzXJClI",
    "Z7caAYctP5scwM7ENXK6lJ",
    "UVzLz6Et9SJX5Yh7nFSk1W"
   ],
   "version": 3
  },
  "kernelspec": {
   "display_name": "machinelearning2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
